{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x000001A9ED043E80> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001A9ED0401C0> root_client=<openai.OpenAI object at 0x000001A9EEB3C340> root_async_client=<openai.AsyncOpenAI object at 0x000001A9ED043EB0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response from LLM\n",
    "\n",
    "result = llm.invoke(\"What is generative AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a category of artificial intelligence systems designed to generate new content, such as text, images, music, or even complex data structures, by learning from existing data. These systems use models, often based on deep learning techniques, to understand patterns and structures in the input data and then produce novel outputs that resemble the original data set. Some popular generative AI models include Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and transformer-based models like GPT (Generative Pre-trained Transformer).\\n\\nGenerative AI has a wide range of applications, including:\\n\\n1. **Text Generation**: Creating human-like text for applications like chatbots, content creation, and translation services.\\n2. **Image and Video Creation**: Producing realistic images or videos, often used in design, entertainment, or creating deepfakes.\\n3. **Music and Sound Generation**: Composing music or generating sound effects.\\n4. **Data Augmentation**: Generating synthetic data to augment training datasets for machine learning models.\\n5. **Design and Art**: Assisting in creating artwork or design elements by generating new ideas or concepts.\\n\\nThese technologies are transforming industries by automating creative processes, enhancing productivity, and enabling new forms of expression. However, they also raise ethical considerations regarding authenticity, copyright, and the potential for misuse.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 274, 'prompt_tokens': 12, 'total_tokens': 286, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'stop', 'logprobs': None} id='run-30e3da84-f1b9-47bc-9bcb-bac8125614ca-0' usage_metadata={'input_tokens': 12, 'output_tokens': 274, 'total_tokens': 286}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an Expert AI Engineer. Provide me Answers based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ChatPrompt Template\n",
    "\n",
    "\n",
    "\n",
    "#this will tell how the LLM model is to behave like\n",
    "# system = the LLM \n",
    "# user = you and me providing inputs as question for the system i.e LLM\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', 'You are an Expert AI Engineer. Provide me Answers based on the question'),\n",
    "        ('user', '{input}')\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is a platform developed by LangChain, designed to enhance the development, testing, and monitoring of applications that utilize large language models (LLMs). It provides a user-friendly interface for developers to create and fine-tune language model applications more effectively. The platform offers features for debugging and evaluating LLM behavior, ensuring that the models perform as expected in various scenarios. By offering tools for better model management, Langsmith aims to simplify the process of integrating and maintaining LLM-based solutions in real-world applications.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 102, 'prompt_tokens': 33, 'total_tokens': 135, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'stop', 'logprobs': None} id='run-d5a38fbf-7bce-4124-a2f4-2cf730d48778-0' usage_metadata={'input_tokens': 33, 'output_tokens': 102, 'total_tokens': 135}\n"
     ]
    }
   ],
   "source": [
    "## Chain\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "\n",
    "response = chain.invoke({\"input\": 'Can you tell me About Langsmith?'})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a platform that offers tools for debugging and monitoring applications built with language models. It was created by LangChain to provide developers with the ability to track the performance and behavior of their applications in real-time. Langsmith offers interactive dashboards and analytical tools that help in understanding how language models are interacting with users and performing tasks. This includes tracking usage patterns, error rates, latency, and other key metrics that are crucial for optimizing and improving language model applications. Langsmith is particularly useful for developers who are building complex AI systems and need detailed insights into the operations of their language models to ensure they are functioning efficiently and effectively.\n"
     ]
    }
   ],
   "source": [
    "## stroutput parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "Output_Parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | Output_Parser\n",
    "\n",
    "response = chain.invoke({\"input\": 'Can you tell me About Langsmith?'})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
